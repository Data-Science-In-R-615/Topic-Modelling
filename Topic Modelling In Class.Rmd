---
title: "Topic Modelling In Class"
author: "Vajinder"
date: "2024-11-01"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r, echo=FALSE, warning=FALSE}
library(tidyverse)
library(topicmodels)
library(tidytext)
library(lexicon)
library(factoextra)
library(wordcloud)

#30 topics, tune the K parameter
```

## Including Plots

You can also embed plots, for example:

```{r }
movie <- read.csv("movie_plots.csv")
movies_genre <- read.csv("movie_plots_with_genres.csv")
```


```{r }
plots <- movies_genre |> unnest_tokens(word,Plot)
plot_word_counts <- plots |>  
  anti_join(stop_words) |> 
  count(Movie.Name, word, sort=TRUE)

data("freq_first_names")

first_names <- tolower(freq_first_names$Name)
plot_word_counts <- plot_word_counts |> 
  filter(!(word %in% first_names))
```


```{r }

dtm <- plot_word_counts |>  
  cast_dtm(Movie.Name, word, n)

dtm
```


```{r }
lda <- LDA(dtm, k = 20, control = list(seed = 1234))

top_terms <- terms(lda, 10)  

```

LDA with 30 topics
plot_lda <- LDA(plot_dtm, k = 30, control = list(seed = 1066))
beta - words per topics
#retrieving gammas
gamma - topics per documents
Notes taken during the class : (plot_ga,,a <- tidy(plots_lda, matrix = "gamma")
cluster ( how similar movies are based on the genre)
multinomial extension of beta distribution - drichlet distribution)

```{r}
betas <- tidy(lda, matrix = "beta")
gammas <- tidy(lda, matrix = "gamma")
gammas <- gammas |>  pivot_wider(names_from = topic, values_from = gamma)
```

Take highest gamma for each movie to get the top movie by topic

```{r}
top_movies <- gammas |>
  pivot_longer(cols = `1`:`20`, names_to = "topic", values_to = "gamma") |> 
  group_by(document) |>  
  slice_max(gamma, n = 1) |>  
  ungroup() |>
  select(document, topic, gamma)  
```

But do get a more detailed look, we need to cluster the movies into 10 clusters by topic
```{r}
library(dplyr)
cluster <- kmeans(gammas |>  select(-document),10)
fviz_cluster(cluster, data = gammas |> select(-document))
movies_genre <- movies_genre |>
  distinct(Movie.Name, .keep_all = TRUE)
clusters <- cluster[["cluster"]]
cluster$cluster <- clusters
movies_genre$cluster <- clusters
```

Creating clusters
```{r}
gammas <- gammas |>
  left_join(movies_genre |> select(Movie.Name, cluster), by = c("document" = "Movie.Name"))
cluster_1 <- gammas |> filter(cluster == 1)
cluster_2 <- gammas |> filter(cluster == 2)
cluster_3 <- gammas |> filter(cluster == 3)
cluster_4 <- gammas |> filter(cluster == 4)
cluster_5 <- gammas |> filter(cluster == 5)
cluster_6 <- gammas |> filter(cluster == 6)
cluster_7 <- gammas |> filter(cluster == 7)
cluster_8 <- gammas |> filter(cluster == 8)
cluster_9 <- gammas |> filter(cluster == 9)
cluster_10 <- gammas |> filter(cluster == 10)
```


Find which topic is most associated with each cluster
```{r}
col_avg <- function(df) {
  selected_columns <- df |>
    select(`1`:`20`)
  
  column_averages <- colMeans(selected_columns, na.rm = TRUE)
  
  return(column_averages)
}
averages_cluster_5 <- col_avg(cluster_5)
print(averages_cluster_5)
```
All of these probablities are pretty small numbers except 3,6, 7, 8 and 20 indicating cluster 5 is most associated with these three topics. 

Make word clouds
```{r}
wordcloud <- function(topic_number) {
  top_words <- betas |>
    filter(topic == topic_number) |>
    top_n(30, beta) |>   
    arrange(desc(beta))
  
  wordcloud::wordcloud(words = top_words$term, 
            freq = top_words$beta, 
            min.freq = 0, 
            scale = c(3, 0.5),   
            random.order = FALSE, 
            colors = brewer.pal(8, "Dark2"))
}
top_terms <- terms(lda, 10)
avg_9 <- col_avg(cluster_9)
print(avg_9)
```

Lets make some fun word clouds
```{r}
wordcloud(1)
wordcloud(2)
wordcloud(3)
```

I got help from Jon and jordan for the probabilities and cloud part. I hadn't added cloud in the original file.
